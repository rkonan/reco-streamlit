import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from model import load_model, predict,load_tflite_dyna_model,load_tflite_ptq_model
import cv2
import streamlit as st
from PIL import Image
import numpy as np
import os
import requests
#from tensorflow.keras.applications.efficientnet import  preprocess_input
from tensorflow.keras.preprocessing import image
import time
from io import BytesIO
import base64
import tensorflow as tf

import numpy as np
import tensorflow as tf
from tf_keras_vis.gradcam import Gradcam
from tf_keras_vis.utils import normalize

import numpy as np
import tensorflow as tf
from tf_keras_vis.saliency import Saliency
from tf_keras_vis.utils import normalize
import numpy as np
import tensorflow as tf
from tf_keras_vis.saliency import Saliency
from tf_keras_vis.utils import normalize
import logging

from streamlit_autorefresh import st_autorefresh

import logging

confidence_threshold=0.4
entropy_threshold=1.5

logging.basicConfig(
    level=logging.INFO,  # ou logging.DEBUG
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)

logger = logging.getLogger(__name__)
model_float32= load_model()
model_dynamique=load_tflite_dyna_model()
model_ptq=load_tflite_ptq_model()
API_HEALTH = "http://0.0.0.0:8590/health"
API_URL = "http://0.0.0.0:8590/predict"
class_names = [
    'Apple_Apple_scab',
    'Apple_Black_rot',
    'Apple_Cedar_apple_rust',
    'Apple_Healthy',
    'Blueberry_Healthy',
    'Cassava_Healthy',
    'Cassava_bacterial_blight',
    'Cassava_brown_streak_disease',
    'Cassava_green_mottle',
    'Cassava_mosaic_disease',
    'Cherry_Healthy',
    'Cherry_Powdery_mildew',
    'Corn_Cercospora_leaf_spot Gray_leaf_spot',
    'Corn_Common_rust_',
    'Corn_Healthy',
    'Corn_Northern_Leaf_Blight',
    'Grape_Black_rot',
    'Grape_Esca_(Black_Measles)',
    'Grape_Healthy',
    'Grape_Leaf_blight_(Isariopsis_Leaf_Spot)',
    'Orange_Haunglongbing_(Citrus_greening)',
    'Peach_Bacterial_spot',
    'Peach_Healthy',
    'Pepper,_Bacterial_spot',
    'Pepper,_Healthy',
    'Potato_Early_blight',
    'Potato_Healthy',
    'Potato_Late_blight',
    'Raspberry_Healthy',
    'Rice_Bacterialblight',
    'Rice_Blast',
    'Rice_Brownspot',
    'Rice_Tungro',
    'Rose_Healthy',
    'Rose_Rose_Rust',
    'Rose_Rose_sawfly_Rose_slug',
    'Soybean_Healthy',
    'Squash_Powdery_mildew',
    'Strawberry_Healthy',
    'Strawberry_Leaf_scorch',
    'Sugarcane_Healthy',
    'Sugarcane_Mosaic',
    'Sugarcane_RedRot',
    'Sugarcane_Rust',
    'Sugarcane_Yellow',
    'Tomato_Bacterial_spot',
    'Tomato_Early_blight',
    'Tomato_Healthy',
    'Tomato_Late_blight',
    'Tomato_Leaf_Mold',
    'Tomato_Septoria_leaf_spot',
    'Tomato_Spider_mites Two-spotted_spider_mite',
    'Tomato_Target_Spot',
    'Tomato_Tomato_Yellow_Leaf_Curl_Virus',
    'Tomato_Tomato_mosaic_virus'
]

st.title("üåø Projet reconnaissance plantes et maladies")

# # st.markdown(
#     """
#     <h1 style='
#         color: green; 
#         font-family: "Arial Black", Gadget, sans-serif; 
#         text-align: center; 
#         text-shadow: 2px 2px #b0e57c;
#         padding: 10px;
#     '>
#         Projet reconnaissance plantes et maladies
#     </h1>
#     """, 
#     unsafe_allow_html=True
# )


st.sidebar.title("Navigation")
pages=["Le projet","Dataset et Exploration",  "Mod√©lisation","Analyses","Pr√©diction","Perspectives","About"]
page=st.sidebar.radio("Aller vers", pages)

if page == pages[0] : 
  st.write("### Home")
  

if page == pages[1] : 
   st.write("### DataVizualization")


if page == pages[2] : 
  st.write("### Mod√©lisation")
  

def check_api_status(url="http://localhost:8000/health"):
    try:
        response = requests.get(url, timeout=2)
        if response.status_code == 200:
            return True
    except Exception:
        pass
    return False
def extract_class_name(filename):
    """
    Extrait 'Plante___Maladie' depuis un nom de fichier du type :
    'Plante___Maladie___<ID>.JPG'
    """
    return "___".join(filename.split("___")[:2])

def predict_via_api(image_pil, api_url, mode="single",show_heatmap=False):
    logger.info("üñºÔ∏è Pr√©paration de l'image pour l'envoi √† l'API...")

    # Conversion de l'image en base64
    buffered = BytesIO()
    image_pil.save(buffered, format="JPEG")
    img_bytes = buffered.getvalue()
    img_b64 = base64.b64encode(img_bytes).decode("utf-8")
    
    # Construction de l'URL
    url = f"{api_url}?show_heatmap={str(show_heatmap).lower()}"
    url = f"{url}&mode={str(mode).lower()}"
    logger.info(f"üåê Envoi de la requ√™te POST √† l'API : {url}")

    payload = {"image": img_b64}
    
    try:
        response = requests.post(url, json=payload)
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la requ√™te API : {e}")
        return None, None, [], [], []

    if response.status_code != 200:
        logger.error(f"‚ùå Erreur API : code {response.status_code} ‚Äì {response.text}")
        return None, None, [], [], []

    result = response.json()

    logger.info("‚úÖ R√©ponse re√ßue avec succ√®s.")

    # Interpr√©tation du nom de classe
    if isinstance(result["predicted_class"], int):
        pred_class_name = class_names[result["predicted_class"]]
    else:
        pred_class_name = result["predicted_class"]

    logger.info(f"üìå Pr√©diction : {pred_class_name} avec confiance {result['confidence']:.4f}")

    gradcam_images = []

    if show_heatmap:
        logger.info(f"üî• G√©n√©ration des heatmaps pour {len(result['models_heatmaps'])} mod√®les...")
        for idx, heatmap in enumerate(result["models_heatmaps"]):
            heatmap_array = np.array(heatmap)
            cam_overlay = apply_heatmap_on_image(image_pil, heatmap_array)
            gradcam_images.append(cam_overlay)
            logger.info(f"üñºÔ∏è Heatmap g√©n√©r√©e pour le mod√®le {result['models'][idx]}")

    return (
        pred_class_name,
        result["confidence"],
        result["models"],
        result["models_predictions"],
        result["models_confidences"],
        gradcam_images
    )
    
def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    """
    Calcule la Grad-CAM heatmap pour une image donn√©e et un mod√®le Keras.

    Args:
      img_array (numpy array): image d'entr√©e preprocess√©e, shape (1, H, W, C)
      model (tf.keras.Model): mod√®le Keras complet (avec la t√™te softmax)
      last_conv_layer_name (str): nom de la derni√®re couche conv (ex: 'top_conv' dans EfficientNetB0)
      pred_index (int, optional): indice de la classe cibl√©e. Par d√©faut la classe pr√©dite par le mod√®le.

    Returns:
      heatmap (numpy array): heatmap 2D normalis√©e entre 0 et 1
    """

    # 1. R√©cup√©rer la derni√®re couche conv
    #back_bone=model.get_layer("efficientnetv2-m")
    back_bone=model
    last_conv_layer = back_bone.get_layer(last_conv_layer_name)

    # 2. Cr√©er un mod√®le interm√©diaire qui donne les activations de la derni√®re couche conv
    # et la sortie finale du mod√®le
    grad_model = tf.keras.models.Model(
        [model.inputs], [last_conv_layer.output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]

    # 3. Calculer le gradient des logits de la classe cible par rapport aux activations conv
    grads = tape.gradient(class_channel, conv_outputs)

    # 4. Moyenne globale des gradients sur les axes spatiaux (H, W)
    pooled_grads = tf.reduce_mean(grads, axis=(1, 2))

    # 5. Pond√©rer chaque canal des activations par les gradients moyens
    conv_outputs = conv_outputs[0]
    pooled_grads = pooled_grads[0]

    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)

    # 6. Normaliser la heatmap entre 0 et 1
    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-8)
    heatmap = heatmap.numpy()

    return heatmap



# Configurer le logger (√† faire une fois dans ton script principal)
logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')

def compute_saliency_map(model, image_array, class_index=None):
    """
    Calcule la carte de saillance avec tf-keras-vis Saliency.

    Args:
        model: tf.keras.Model.
        image_array: np.array, shape (H, W, 3), float32, pr√©-trait√©e.
        class_index: int ou None. Si None, prend la classe pr√©dite.

    Returns:
        saliency_map: np.array float32, normalis√©e entre 0 et 1, shape (H, W).
    """
    logging.info("D√©but du calcul de la carte de saillance")

    if image_array.ndim == 3:
        input_tensor = np.expand_dims(image_array, axis=0)
        logging.debug(f"Image d'entr√©e dimensionn√©e de {image_array.shape} √† {input_tensor.shape} (batch)")
    else:
        input_tensor = image_array
        logging.debug(f"Image d'entr√©e d√©j√† batch√©e avec shape {input_tensor.shape}")

    saliency = Saliency(model)
    logging.info("Objet Saliency initialis√©")

    def loss(output):
        # output shape: (batch_size, num_classes)
        if class_index is None:
            class_index_local = tf.argmax(output[0])
            logging.info(f"Classe cible non sp√©cifi√©e, utilisation de la classe pr√©dite: {class_index_local.numpy()}")
        else:
            class_index_local = class_index
            logging.info(f"Classe cible sp√©cifi√©e: {class_index_local}")
        return output[:, class_index_local]

    saliency_map = saliency(loss, input_tensor)
    logging.info("Calcul de la carte de saillance termin√©")

    saliency_map = saliency_map[0]  # shape (H, W, 3)
    logging.debug(f"Shape de la carte brute: {saliency_map.shape}")

    # Prendre le max absolu sur les canaux couleurs pour avoir une carte 2D
    
    if saliency_map.ndim == 3:
        saliency_map = np.max(np.abs(saliency_map), axis=-1)
    else:
        saliency_map = np.abs(saliency_map)
    logging.debug(f"Shape de la carte apr√®s r√©duction canaux: {saliency_map.shape}")

    # Normaliser la carte entre 0 et 1
    saliency_map = normalize(saliency_map)
    logging.info("Normalisation de la carte de saillance termin√©e")

    return saliency_map






def compute_gradcam(model, image_array, class_index=None, layer_name=None):
    """
    Calcule la carte Grad-CAM pour une image et un mod√®le Keras.

    Args:
        model: tf.keras.Model.
        image_array: np.array (H, W, 3), float32, pr√©-trait√©e.
        class_index: int ou None, index de la classe cible. Si None, classe pr√©dite.
        layer_name: str ou None, nom de la couche convolutionnelle √† utiliser. Si None, derni√®re conv.

    Returns:
        gradcam_map: np.array (H, W), normalis√©e entre 0 et 1.
    """

    if image_array.ndim == 3:
        input_tensor = np.expand_dims(image_array, axis=0)
    else:
        input_tensor = image_array

    gradcam = Gradcam(model, clone=False)

    def loss(output):
        if class_index is None:
            class_index_local = tf.argmax(output[0])
        else:
            class_index_local = class_index
        return output[:, class_index_local]

    # Choisir la couche √† utiliser pour GradCAM
    if layer_name is None:
        # Si non sp√©cifi√©, chercher la derni√®re couche conv 2D
        for layer in reversed(model.layers):
            if 'conv' in layer.name and len(layer.output_shape) == 4:
                layer_name = layer.name
                break
        if layer_name is None:
            raise ValueError("Aucune couche convolutionnelle 2D trouv√©e dans le mod√®le.")

    cam = gradcam(loss, input_tensor, penultimate_layer=layer_name)
    cam = cam[0]

    # Normaliser entre 0 et 1
    cam = normalize(cam)

    return cam



def compute_saliency_map_basic(model, image_array, class_index=None):
    """
    Calcule la carte de saillance (saliency map) d'une image pour un mod√®le donn√©.

    Args:
        model : mod√®le Keras TensorFlow.
        image_array : np.array, image d'entr√©e pr√©-trait√©e, shape (H, W, 3), float32.
        class_index : int ou None, index de la classe cible. 
                      Si None, on prend la pr√©diction la plus probable.

    Returns:
        saliency_map : np.array, carte de saillance normalis√©e (valeurs entre 0 et 1), shape (H, W).
    """
    if image_array.ndim == 3:
        image_tensor = tf.expand_dims(image_array, axis=0)
    else:
        image_tensor = tf.convert_to_tensor(image_array)

    with tf.GradientTape() as tape:
        tape.watch(image_tensor)
        preds = model(image_tensor)
        if class_index is None:
            class_index = tf.argmax(preds[0])
        class_score = preds[:, class_index]

    grads = tape.gradient(class_score, image_tensor)  # gradient de la sortie par rapport √† l'image
    saliency = tf.reduce_max(tf.abs(grads), axis=-1)[0]  # max sur canaux couleur, retirer batch

    # Normaliser entre 0 et 1
    saliency = (saliency - tf.reduce_min(saliency)) / (tf.reduce_max(saliency) - tf.reduce_min(saliency) + 1e-10)
    return saliency.numpy()

def apply_heatmap_on_image(image_pil, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET):
    """
    Superpose le heatmap (2D float entre 0 et 1) sur l‚Äôimage PIL d'origine.
    """
    # Convert PIL -> array
    image = np.array(image_pil.resize((heatmap.shape[1], heatmap.shape[0]))).copy()  # (H, W, 3)
    # Convert heatmap to [0, 255] uint8
    heatmap = np.uint8(255 * heatmap)
    
    # Apply colormap
    heatmap_colored = cv2.applyColorMap(heatmap, colormap)  # (H, W, 3), BGR
    
    # Convert BGR to RGB
    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)
    
    # Superpose avec transparence
    superimposed_img = cv2.addWeighted(image, 1 - alpha, heatmap_colored, alpha, 0)
    
    return Image.fromarray(superimposed_img)

def overlay_heatmap(heatmap, image_pil, alpha=0.4):
    heatmap = np.uint8(255 * heatmap)
    heatmap = Image.fromarray(heatmap).resize(image_pil.size)
    heatmap = heatmap.convert("RGBA")
    image_pil = image_pil.convert("RGBA")
    blended = Image.blend(image_pil, heatmap, alpha)
    return blended

def compute_entropy_safe(probas):
    probas = np.array(probas)
    # On garde uniquement les probabilit√©s strictement positives
    mask = probas > 0
    entropy = -np.sum(probas[mask] * np.log(probas[mask]))
    return entropy
if page == pages[4]:
    st.title("üß† Pr√©dictions sur plusieurs images")

    is_online = st.toggle("Mode en ligne", value=True)
    api_up = check_api_status(API_HEALTH) and is_online

    if api_up:
        plan = st.radio("S√©lectionnez votre plan :", ["Standard", "Premium"])

    if api_up:
        st.success("‚úÖ Service API disponible")
    else:
        st.error("‚ùå Service API indisponible. Utilisation du mod√®le local.")
        is_online = False

    # üéõÔ∏è S√©lecteur de mod√®le avec infobulle
        model_choice = st.radio(
        "S√©lectionnez le mod√®le local (hors API) :",
        (
            "Quantifi√© Dynamique ‚Äì rapide ‚Äì mobile standard",
            "Quantifi√© PTQ ‚Äì ultra rapide ‚Äì mobile ancien",
            "Float32 ‚Äì lourd ‚Äì mobile puissant"
        ),
        index=0,
        help="Choisissez en fonction de la puissance de votre appareil : PTQ pour une compatibilit√© maximale, Dynamique pour un bon compromis, Float32 pour une visualisation avanc√©e."
        )

        # Description dynamique
        if "Dynamique" in model_choice:
            st.info("üîπ Mod√®le Quantifi√© Dynamique : rapide, id√©al pour les mobiles d'entr√©e de gamme avec des ressources limit√©es. Grad-CAM indisponible.")
            model_tflite=model_dynamique
        elif "PTQ" in model_choice:
            st.info("üîπ Mod√®le Quantifi√© PTQ : ultra rapide, parfait pour les mobiles tr√®s bas de gamme ou anciens. Grad-CAM indisponible.")
            model_tflite=model_ptq
        else:
            st.info("üîπ Mod√®le Float32 : plus lourd, n√©cessite un mobile puissant ou r√©cent. Grad-CAM disponible pour visualiser les activations.")

    # üëâ Tu peux continuer ici avec ton chargement de mod√®le en fonction du choix

    show_gradcam = False
    if is_online or (not is_online and "Float32" in model_choice):
        show_gradcam = st.checkbox("Afficher Grad-CAM", value=False)
    else:
        st.info("‚ÑπÔ∏è Grad-CAM non disponible avec mod√®le quantifi√©")

    uploaded_files = st.file_uploader(
        "D√©posez plusieurs images ou choisissez-les :",
        type=["jpg", "jpeg", "png"],
        accept_multiple_files=True
    )

    if st.button("üöÄ Lancer les pr√©dictions sur toutes les images"):
        if uploaded_files:
            total = len(uploaded_files)
            progress_bar = st.progress(0)
            progress_text = st.empty()
            summary_placeholder = st.empty()

            start_time = time.time()
            results = []

            def predict_one(uploaded_file):
                img = Image.open(uploaded_file).convert("RGB")
                file_name = os.path.basename(uploaded_file.name)
                true_class = extract_class_name(file_name)
                confidence = 0.0

                try:
                    if is_online and api_up:
                        mode_call = "single" if plan == "Standard" else "voting"
                        pred_class_name, confidence, models_names, models_predictions, models_confidences, gradcam_images = predict_via_api(
                            img, API_URL, mode_call, show_gradcam
                        )
                    else:
                        if model_choice.startswith("Quantifi√©"):
                            preds = model_tflite.predict(img.resize((224, 224)))
                            pred_class_idx = np.argmax(preds)
                            confidence = float(np.max(preds))
                            pred_class_name = class_names[pred_class_idx]
                            entropy = compute_entropy_safe(preds)
                            is_uncertain = confidence< confidence_threshold or entropy > entropy_threshold
                            models_names = ["Mod√®le quantifi√© (TFLite)"]
                            gradcam_images = []
                        else:
                            preds, image_data = model_float32.predict(img.resize((224, 224)))
                            pred_class_idx = np.argmax(preds)
                            confidence = float(np.max(preds))
                            pred_class_name = class_names[pred_class_idx]
                            entropy = entropy = compute_entropy_safe(preds)
                            is_uncertain = confidence< confidence_threshold or entropy > entropy_threshold
                            models_names = ["Mod√®le float32"]
                            gradcam_images = []
                            if show_gradcam and not is_uncertain :
                                #heatmap = compute_saliency_map(model_float32.get_model(), image_data)
                                heatmap= compute_gradcam(model_float32.get_model(),image_data,class_index=None,layer_name="top_conv")
                                cam_overlay = apply_heatmap_on_image(img.resize((224, 224)), heatmap,0.5)
                                gradcam_images.append(cam_overlay)

                    return {
                        "file_name": file_name,
                        "image_obj":img,
                        "true_class": true_class,
                        "pred_class_name": pred_class_name,
                        "confidence": confidence,
                        "entropy": entropy,
                        "is_uncertain":is_uncertain,
                        "models_names": models_names,
                        "models_predictions": models_predictions if is_online and api_up else [],
                        "models_confidences": models_confidences if is_online and api_up else [],
                        "gradcam_images": gradcam_images,
                        "error": None
                    }
                except Exception as e:
                    return {
                        "file_name": file_name,
                        "error": str(e)
                    }

            if is_online and api_up:
                # Mode API avec parall√©lisation
                import concurrent.futures

                with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                    futures = {executor.submit(predict_one, f): f for f in uploaded_files}
                    for i, future in enumerate(concurrent.futures.as_completed(futures)):
                        result = future.result()
                        results.append(result)
                        progress = int((i + 1) / total * 100)
                        progress_bar.progress(progress)
                        progress_text.text(f"üñºÔ∏è Image {i+1}/{total} trait√©e...")
            else:
                # Mode local s√©quentiel (non parall√©lis√©)
                for i, f in enumerate(uploaded_files):
                    result = predict_one(f)
                    results.append(result)
                    progress = int((i + 1) / total * 100)
                    progress_bar.progress(progress)
                    progress_text.text(f"üñºÔ∏è Image {i+1}/{total} trait√©e...")

            elapsed = time.time() - start_time

            # Affichage r√©sum√©
            summary_placeholder.markdown(
                f"""
                üéâ **Toutes les pr√©dictions sont termin√©es !**  
                üïí {total} image(s) trait√©e(s) en {elapsed:.2f} secondes.
                """
            )

            # Affichage des r√©sultats d√©taill√©s apr√®s la boucle
            for res in results:
                if res.get("error"):
                    st.error(f"Erreur pour `{res['file_name']}` : {res['error']}")
                    continue
                
                if not res['is_uncertain']:
                    st.image(res['image_obj'], caption=f"Image : {res['file_name']}", use_container_width=True)
                    st.markdown("### üîç R√©sultat de la pr√©diction")
                    st.write(f"üìÅ Nom du fichier : `{res['file_name']}`")
                    st.write(f"üè∑Ô∏è Vraie classe (extrait nom) : `{res['true_class']}`")
                    st.write(f"‚úÖ Classe pr√©dite : `{res['pred_class_name']}`")
                    st.write(f"üìä Confiance : **{res['confidence']*100:.2f}%**")
                    st.write(f"üìà Entropie : **{res['entropy']:.3f}**")
                    if is_online:
                        if plan == "Standard":
                            st.info(f"üß† Mode : **Standard** ‚Äî 1 mod√®le utilis√© : `{res['models_names'][0]}`")
                        elif plan == "Premium":
                            st.success(f"üåü Mode : **Premium** ‚Äî Mod√®les utilis√©s : {', '.join(res['models_names'])}")
                            if len(res['models_names']) > 1:
                                with st.expander("üîé D√©tails des votes de chaque mod√®le"):
                                    for i, model_name in enumerate(res['models_names']):
                                        model_pred_class = res['models_predictions'][i]
                                        model_confidence = 100 * res['models_confidences'][i]
                                        st.write(f"üß† **{model_name}** : classe `{class_names[model_pred_class]}` avec confiance **{model_confidence:.2f}%**")
                    else:
                        st.warning(f"‚ö†Ô∏è Mode local : mod√®le utilis√© `{res['models_names'][0]}`")

                    if res['gradcam_images']:
                        with st.expander("üñºÔ∏è Visualisations Grad-CAM"):
                            for i, img_cam in enumerate(res['gradcam_images']):
                                st.image(img_cam, caption=f"Salience - Mod√®le : {res['models_names'][i]}")
                else:
                     st.image(res['image_obj'], caption=f"Image : {res['file_name']}", use_container_width=True)
                     st.warning("‚ö†Ô∏è Impossible de donner une pr√©diction fiable sur cette image.", icon="‚ö†Ô∏è")
                     st.write(f"üìä **Confiance trop faible : {res['confidence'] * 100:.2f}%**")
                     st.write(f"üìà **Entropie √©lev√©e : {res['entropy']:.3f}**")
                     st.info("üëâ Veuillez v√©rifier que l'image est bien celle d'une plante.", icon="üîç")

        else:
            st.warning("‚ö†Ô∏è Veuillez uploader au moins une image.")
